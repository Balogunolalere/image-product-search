# -*- coding: utf-8 -*-
"""image_product_search.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13YXR1JsFlKVpUOiv7_AJblNd6qG2HtnB
"""

!pip install "docarray[hnswlib]" torch torchvision aiohttp aiofiles IPython git+https://github.com/facebookresearch/ImageBind.git

import asyncio
from glob import glob
from urllib.parse import urlparse
from IPython.display import Image, display, HTML

import torch
import pandas as pd
import aiohttp
from aiofiles import open as aioopen
from docarray import DocList, BaseDoc
from docarray.documents import TextDoc, ImageDoc, AudioDoc
from docarray.typing import NdArray
from docarray.index import HnswDocumentIndex
from imagebind import data as ibdata
from imagebind.models import imagebind_model
from imagebind.models.imagebind_model import ModalityType
import nest_asyncio

nest_asyncio.apply()

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = imagebind_model.imagebind_huge(pretrained=True).eval().to(device)

def embed(doc):
    with torch.no_grad():
        modality = {
            TextDoc: (ModalityType.TEXT, ibdata.load_and_transform_text),
            ImageDoc: (ModalityType.VISION, ibdata.load_and_transform_vision_data),
            AudioDoc: (ModalityType.AUDIO, ibdata.load_and_transform_audio_data)
        }.get(type(doc))

        if not modality:
            raise ValueError('Unsupported document type')

        modality_type, transform_func = modality
        input_data = [doc.text if isinstance(doc, TextDoc) else doc.url]
        embedding = model({modality_type: transform_func(input_data, device)})[modality_type]
        doc.embedding = embedding.cpu().numpy()[0]
    return doc

data = pd.read_json('/content/jendol.json')
image_urls = data['Images'].tolist()
save_directory = 'jendol_images'

async def download_image(session, url, save_path):
    async with session.get(url) as response:
        if response.status == 200:
            async with aioopen(save_path, 'wb') as f:
                await f.write(await response.read())
            print(f"Downloaded: {url}")
        else:
            print(f"Failed to download: {url}")

async def download_all_images(urls, save_dir):
    os.makedirs(save_dir, exist_ok=True)
    async with aiohttp.ClientSession() as session:
        tasks = [download_image(session, url, os.path.join(save_dir, os.path.basename(urlparse(url).path))) for url in urls]
        await asyncio.gather(*tasks)

asyncio.run(download_all_images(image_urls, save_directory))

# Add embeddings to the DataFrame
data['embedding'] = data['Images'].apply(lambda url: embed(ImageDoc(url=os.path.join(save_directory, os.path.basename(urlparse(url).path)))).embedding)

data

#save the data as json
data.to_json('/content/embedded_jendol.json')

class ProductDoc(BaseDoc):
    name: str
    price: str
    image_url: str
    embedding: NdArray[1024] = None

doc_index = HnswDocumentIndex[ProductDoc](work_dir='/store')

batch_size = 1000

for i in range(0, len(data), batch_size):
    batch = data.iloc[i:i+batch_size]
    docs = DocList[ProductDoc](
        ProductDoc(name=row['Names'], price=row['Prices'], image_url=row['Images'], embedding=row['embedding'])
        for _, row in batch.iterrows()
    )
    doc_index.index(docs)

print(f"Indexed {len(data)} documents in total.")

query_embedding = embed(TextDoc(text='deodorant')).embedding
matches = doc_index.find(query_embedding, search_field='embedding', limit=3)

for match in matches.documents:
    display(Image(url=match.image_url))
    display(HTML(f"<b>{match.name}</b><br>Price: {match.price}"))

# search using image
query_embedding = embed(ImageDoc(url='/content/pepsi.jpeg')).embedding
matches = doc_index.find(query_embedding, search_field='embedding', limit=5)

for match in matches.documents:
    display(Image(url=match.image_url))
    display(HTML(f"<b>{match.name}</b><br>Price: {match.price}"))

